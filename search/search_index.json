{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DEVON Documentation","text":"<p>\"DEVON manages the models. KITT tests them.\"</p> <p>DEVON (Discovery Engine and Vault for Open Neural models) is a CLI tool and REST API for discovering, downloading, and managing LLM models from HuggingFace and other sources. It gives you a single workflow to search massive model repositories, pull weights to local storage, and keep your model vault organized -- so you can spend your time testing, not hunting for files. Run it locally as a CLI or deploy it as a containerized API for remote model management.</p>"},{"location":"#feature-highlights","title":"Feature Highlights","text":"Smart Search Filter models by provider, size, parameter count, format, license, and more. Results are sorted by popularity and displayed in rich terminal tables. Easy Download Pass a HuggingFace URL or a model ID. Downloads resume automatically if interrupted -- no need to start over. Local Vault Models are stored in a clean directory hierarchy with a JSON index. Track total disk usage at a glance with <code>devon status</code>. KITT Integration Export downloaded model paths in a format KITT can consume directly, bridging model management and inference testing. Source Plugin System HuggingFace is built in, but the architecture supports additional model sources through a plugin registry with a simple ABC interface. YAML Configuration Override storage paths, search defaults, and display options in a single config file. DEVON deep-merges your overrides with sensible defaults. REST API Run <code>devon serve</code> to expose every capability over HTTP. The FastAPI-based server supports optional bearer token auth and mirrors all CLI operations. Docker Ready Ship DEVON as a container with a single volume mount. Models, index, and config all live under <code>/data</code> for easy host-path binding."},{"location":"#quick-links","title":"Quick Links","text":"Section What you will find Getting Started Installation, environment setup, and your first model download Guides Task-focused walkthroughs -- searching, downloading, managing, REST API, Docker, KITT integration, configuration Reference CLI reference, configuration schema, model metadata, and storage index format Concepts Architecture overview, source plugin system, and storage design Changelog Release history and migration notes"},{"location":"#at-a-glance","title":"At a Glance","text":"<pre><code>devon search --provider qwen --params 30b --size \"&lt;100gb\"\ndevon download Qwen/Qwen2.5-32B-Instruct\ndevon list\ndevon export --format kitt -o models.txt\n\n# Or run as an API server\ndevon serve --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"#related-projects","title":"Related Projects","text":"<p>DEVON is designed to work alongside KITT, the LLM inference engine testing framework. Use DEVON to curate your model collection, then hand the paths to KITT for benchmarking.</p> <ul> <li>KITT Documentation</li> <li>KITT Repository</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to DEVON are documented in this file.</p>"},{"location":"changelog/#110","title":"1.1.0","text":"<ul> <li>REST API \u2014 FastAPI server exposed via <code>devon serve</code><ul> <li>Endpoints: health, search, models (list/info/delete), downloads, storage (status/clean/export)</li> <li>Optional bearer token authentication via <code>DEVON_API_KEY</code></li> <li>App factory with lifespan for shared Settings and ModelStorage</li> </ul> </li> <li>Docker support \u2014 multi-stage Dockerfile and docker-compose.yml<ul> <li>Single <code>/data</code> volume mount for models, index, and config</li> <li>Non-root <code>devon</code> user, built-in healthcheck</li> <li>Configurable via <code>DEVON_PORT</code>, <code>DEVON_DATA_PATH</code>, <code>DEVON_API_KEY</code>, <code>HF_TOKEN</code></li> </ul> </li> <li><code>devon serve</code> command \u2014 start the API server from the CLI<ul> <li><code>--host</code>, <code>--port</code>, <code>--reload</code> options</li> <li>Graceful error if API extras are not installed</li> </ul> </li> <li>Optional <code>api</code> extras \u2014 <code>poetry install --extras api</code> adds FastAPI and Uvicorn without affecting CLI-only installs</li> </ul>"},{"location":"changelog/#100","title":"1.0.0","text":"<ul> <li>Initial release</li> <li>HuggingFace model search with filters (provider, params, size, format, task, license)</li> <li>Model download by URL or ID with resume support</li> <li>Local vault with JSON index and disk usage tracking</li> <li>KITT integration via <code>devon export --format kitt</code></li> <li>YAML configuration with deep merge</li> <li>Source plugin architecture</li> </ul>"},{"location":"concepts/","title":"Concepts","text":"<p>This section covers the key ideas and design decisions behind DEVON. Read these pages to understand why DEVON works the way it does, not just how to use it.</p> <p>If you are looking for exact schemas or command flags, see the Reference section instead.</p>"},{"location":"concepts/#topics","title":"Topics","text":"<ul> <li> <p>Architecture -- Project structure, package layout,   and the data flow from CLI commands through source plugins to local   storage.</p> </li> <li> <p>Source Plugins -- The plugin system that lets   DEVON talk to different model providers. Covers the abstract base class,   the registry, and the built-in HuggingFace implementation.</p> </li> <li> <p>Storage Design -- How DEVON organizes downloaded   models on disk, why it uses a flat JSON index instead of a database, and   how it handles atomic writes and size tracking.</p> </li> </ul>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>DEVON is organized as a set of focused packages under <code>src/devon/</code>. Each package owns one responsibility, and the CLI layer ties them together.</p>"},{"location":"concepts/architecture/#project-structure","title":"Project Structure","text":"<pre><code>src/devon/\n\u251c\u2500\u2500 cli/           # Click commands and the main entry point group\n\u251c\u2500\u2500 api/           # FastAPI REST API (app factory, routers, schemas)\n\u2502   \u2514\u2500\u2500 routers/   # Endpoint handlers (health, search, models, download, storage)\n\u251c\u2500\u2500 sources/       # Model source plugins (ABC, registry, implementations)\n\u251c\u2500\u2500 storage/       # Local model storage and JSON index management\n\u251c\u2500\u2500 search/        # Query parsing and filter logic\n\u251c\u2500\u2500 download/      # Download orchestration with resume support\n\u251c\u2500\u2500 models/        # ModelMetadata dataclass\n\u251c\u2500\u2500 config/        # Settings class with YAML loading and deep merge\n\u2514\u2500\u2500 utils/         # URL parser, size parser, format detection helpers\n</code></pre>"},{"location":"concepts/architecture/#cli","title":"cli","text":"<p>The entry point is <code>devon.cli.main:cli</code>, a Click group that collects sub-commands from individual modules (<code>search_cmd.py</code>, <code>download_cmd.py</code>, <code>serve_cmd.py</code>, etc.). Each command module is self-contained: it parses arguments, calls into the appropriate package, and renders output with Rich.</p>"},{"location":"concepts/architecture/#api","title":"api","text":"<p>A FastAPI application that exposes DEVON's capabilities over HTTP. The <code>create_app()</code> factory in <code>api/app.py</code> initializes shared resources (<code>Settings</code>, <code>ModelStorage</code>) via a lifespan context manager and registers routers for health, search, models, downloads, and storage operations. Routers call the same internal classes the CLI uses -- no logic is duplicated. See the REST API guide for usage.</p>"},{"location":"concepts/architecture/#sources","title":"sources","text":"<p>Defines how DEVON talks to external model providers. The package contains an abstract base class (<code>ModelSource</code>), a registry, and concrete implementations. See Source Plugins for details.</p>"},{"location":"concepts/architecture/#storage","title":"storage","text":"<p>Manages the on-disk model vault and its JSON index. See Storage Design for the file layout and index format.</p>"},{"location":"concepts/architecture/#search","title":"search","text":"<p>Provides query parsing that translates CLI filter flags (provider, parameter count, size, format, task, license) into source-specific API calls.</p>"},{"location":"concepts/architecture/#download","title":"download","text":"<p>Handles downloading model files from a source, including progress tracking and automatic resume of interrupted transfers.</p>"},{"location":"concepts/architecture/#models","title":"models","text":"<p>Contains the <code>ModelMetadata</code> dataclass -- the standard representation of a model across every part of the system.</p>"},{"location":"concepts/architecture/#config","title":"config","text":"<p>Loads <code>~/.config/devon/config.yaml</code>, deep-merges it over built-in defaults, and exposes values through dot-notation access.</p>"},{"location":"concepts/architecture/#utils","title":"utils","text":"<p>Small standalone helpers: URL detection and parsing (<code>URLParser</code>), byte-size formatting (<code>format_bytes</code>, <code>format_number</code>), and format detection.</p>"},{"location":"concepts/architecture/#plugin-registry-pattern","title":"Plugin Registry Pattern","text":"<p>DEVON uses a class-level dictionary registry shared by source plugins:</p> <ol> <li>An abstract base class (<code>ModelSource</code>) defines the interface.</li> <li>A <code>SourceRegistry</code> class holds a <code>dict[str, type[ModelSource]]</code> as a    class attribute.</li> <li>A <code>@register_source</code> decorator adds a source class to the registry at    import time.</li> <li>The <code>sources/__init__.py</code> module imports all concrete sources so that    registration happens automatically when the package is first loaded.</li> </ol> <p>This pattern keeps source implementations decoupled from the rest of the codebase and makes it straightforward to add new providers.</p>"},{"location":"concepts/architecture/#shared-patterns-with-kitt","title":"Shared Patterns with KITT","text":"<p>DEVON and KITT share several conventions:</p> <ul> <li>Poetry for dependency management and virtual environments</li> <li>Click for CLI parsing</li> <li>Rich for terminal output (tables, panels, spinners)</li> <li>Python 3.10+ minimum version</li> <li>Plugin registries with ABC + decorator + class-level dict</li> </ul> <p>This consistency means contributors familiar with one project can navigate the other with minimal ramp-up.</p>"},{"location":"concepts/architecture/#data-flow","title":"Data Flow","text":"<p>A typical operation follows this path, regardless of whether it originates from the CLI or the REST API:</p> <pre><code>CLI command / API request\n  \u2192 Source plugin (search / get_model_info / download_model)\n    \u2192 ModelMetadata dataclass\n      \u2192 ModelStorage (register, index write)\n        \u2192 JSON index on disk\n</code></pre> <ol> <li>The user invokes a CLI command (e.g., <code>devon download Qwen/Qwen2.5-32B</code>)    or sends an HTTP request to the API.</li> <li>The CLI or API router resolves the source plugin and calls its method.</li> <li>The source plugin returns a <code>ModelMetadata</code> instance.</li> <li><code>ModelStorage</code> writes the model files to disk and registers the entry in    the JSON index.</li> <li>The CLI renders a summary with Rich, or the API returns a JSON response.</li> </ol>"},{"location":"concepts/source-plugins/","title":"Source Plugins","text":"<p>DEVON uses a plugin system to support multiple model providers. Each source is a self-contained class that knows how to search, fetch metadata, and download models from one provider.</p>"},{"location":"concepts/source-plugins/#modelsource-abc","title":"ModelSource ABC","text":"<p>The abstract base class lives in <code>devon.sources.base</code> and defines five methods that every source must implement:</p> Method Return Type Description <code>name()</code> <code>str</code> Unique identifier for this source (e.g., <code>\"huggingface\"</code>) <code>is_available()</code> <code>bool</code> Whether the source can be reached right now <code>search(query, **filters)</code> <code>list[ModelMetadata]</code> Search for models matching the query and filters <code>get_model_info(model_id)</code> <code>ModelMetadata</code> Fetch full metadata for a single model <code>download_model(model_id, dest)</code> <code>Path</code> Download model files to <code>dest</code> and return the path <p>All methods are expected to raise descriptive exceptions on failure so the CLI layer can display useful error messages.</p>"},{"location":"concepts/source-plugins/#sourceregistry","title":"SourceRegistry","text":"<p>The registry is defined in <code>devon.sources.registry</code> and uses a class-level dictionary to track available sources:</p> <pre><code>class SourceRegistry:\n    _sources: dict[str, type[ModelSource]] = {}\n\n    @classmethod\n    def get_source(cls, name: str) -&gt; ModelSource: ...\n\n    @classmethod\n    def list_available(cls) -&gt; list[str]: ...\n\n    @classmethod\n    def list_all(cls) -&gt; dict[str, type[ModelSource]]: ...\n</code></pre>"},{"location":"concepts/source-plugins/#register_source-decorator","title":"@register_source Decorator","text":"<p>Sources register themselves at import time using the decorator:</p> <pre><code>from devon.sources.registry import register_source\nfrom devon.sources.base import ModelSource\n\n@register_source\nclass MySource(ModelSource):\n    def name(self) -&gt; str:\n        return \"mysource\"\n    ...\n</code></pre> <p>The <code>sources/__init__.py</code> file imports all concrete source modules so that registration happens automatically when the package loads.</p>"},{"location":"concepts/source-plugins/#huggingface-implementation","title":"HuggingFace Implementation","text":"<p>The built-in HuggingFace source lives in <code>devon.sources.huggingface</code> and depends on the <code>huggingface-hub</code> package (version ^0.32).</p>"},{"location":"concepts/source-plugins/#key-implementation-details","title":"Key Implementation Details","text":"<ul> <li> <p>Search uses <code>HfApi.list_models()</code> with keyword arguments directly   (e.g., <code>author=</code>, <code>library=</code>, <code>search=</code>). The deprecated <code>ModelFilter</code>   class was removed in HuggingFace Hub 2.0 and must not be used.</p> </li> <li> <p>Card data is a <code>ModelCardData</code> object, not a dictionary. Access fields   with <code>getattr(model.card_data, \"license\", None)</code> rather than bracket   notation.</p> </li> <li> <p>Attribute names are snake_case: <code>created_at</code>, <code>last_modified</code>,   <code>card_data</code>, <code>model_id</code>.</p> </li> <li> <p>License may be returned as a list from the API. The implementation   joins multiple values with <code>\", \"</code> before storing in <code>ModelMetadata</code>.</p> </li> <li> <p>Downloads use <code>snapshot_download()</code> from <code>huggingface_hub</code>. As of   v0.32, resume behavior is the default and <code>resume_download=True</code> is no   longer required.</p> </li> </ul>"},{"location":"concepts/source-plugins/#adding-a-new-source","title":"Adding a New Source","text":"<ol> <li>Create a new module under <code>devon/sources/</code> (e.g., <code>ollama.py</code>).</li> <li>Define a class that inherits from <code>ModelSource</code> and implements all five    abstract methods.</li> <li>Decorate the class with <code>@register_source</code>.</li> <li>Import the new module in <code>devon/sources/__init__.py</code>.</li> <li>Add the source name to the <code>sources.enabled</code> list in the default    configuration.</li> </ol> <pre><code># devon/sources/ollama.py\nfrom devon.sources.base import ModelSource\nfrom devon.sources.registry import register_source\n\n@register_source\nclass OllamaSource(ModelSource):\n    def name(self) -&gt; str:\n        return \"ollama\"\n\n    def is_available(self) -&gt; bool:\n        ...\n</code></pre> <p>After these steps the new source will appear in <code>SourceRegistry.list_all()</code> and can be selected with <code>--source ollama</code> on any CLI command.</p>"},{"location":"concepts/storage-design/","title":"Storage Design","text":"<p>DEVON stores downloaded models on disk and tracks them with a JSON index. This page explains the directory layout, index format, and the design decisions behind them.</p>"},{"location":"concepts/storage-design/#directory-structure","title":"Directory Structure","text":"<p>Models are organized under the configured <code>storage.base_path</code> (default <code>~/.cache/devon/models/</code>) using the pattern:</p> <pre><code>models/{source}/{author}/{model}/\n</code></pre> <p>For example:</p> <pre><code>~/.cache/devon/\n\u251c\u2500\u2500 index.json\n\u2514\u2500\u2500 models/\n    \u2514\u2500\u2500 huggingface/\n        \u251c\u2500\u2500 Qwen/\n        \u2502   \u2514\u2500\u2500 Qwen2.5-32B-Instruct/\n        \u2514\u2500\u2500 meta-llama/\n            \u2514\u2500\u2500 Llama-3-70B-Instruct/\n</code></pre> <p>This layout mirrors the <code>author/model</code> convention used by HuggingFace and keeps models from different sources cleanly separated.</p>"},{"location":"concepts/storage-design/#json-index","title":"JSON Index","text":"<p>The index file lives at <code>{base_path}/../index.json</code> -- a sibling of the <code>models/</code> directory. It is a single JSON object where each key is a model identifier in the format:</p> <pre><code>{source}::{model_id}\n</code></pre> <p>For example: <code>huggingface::Qwen/Qwen2.5-32B-Instruct</code>.</p> <p>See the Storage Index reference for the full entry schema.</p>"},{"location":"concepts/storage-design/#why-a-flat-json-file","title":"Why a Flat JSON File","text":"<ul> <li>Simplicity. No external database to install, configure, or migrate.   The index is a single portable file.</li> <li>Transparency. Users can inspect and even hand-edit the index with any   text editor or JSON tool.</li> <li>Portability. Copying the <code>~/.cache/devon/</code> directory to another   machine is enough to move the entire vault.</li> </ul> <p>The trade-off is that concurrent writes from multiple processes are not safe without coordination. For CLI use this is not a practical concern. When running the REST API server, DEVON defaults to a single Uvicorn worker to avoid index corruption from concurrent writes.</p>"},{"location":"concepts/storage-design/#atomic-operations","title":"Atomic Operations","text":"<p>The <code>ModelStorage</code> class uses a read-modify-write pattern with file locking:</p> <ol> <li>Read the entire index into memory.</li> <li>Apply the change (add, update, or remove an entry).</li> <li>Write the full index back to disk.</li> </ol> <p>This keeps the index consistent even if the process is interrupted, because the write replaces the file atomically.</p>"},{"location":"concepts/storage-design/#size-tracking","title":"Size Tracking","text":"<p>Each index entry records a <code>size_bytes</code> value that is calculated at registration time by summing the sizes of all downloaded files. The <code>get_total_size()</code> method sums across every entry to report overall vault usage, which powers the <code>devon status</code> command.</p>"},{"location":"concepts/storage-design/#last-used-tracking","title":"Last-Used Tracking","text":"<p>Every index entry includes a <code>last_used</code> timestamp that is updated each time the model is accessed (for example, by <code>devon info</code> or <code>devon export</code>). The <code>devon clean --unused --days N</code> command uses this timestamp to identify models that have not been touched in <code>N</code> days, making it easy to reclaim disk space without manually deciding which models to keep.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This section walks you through installing DEVON and downloading your first model. By the end you will have a working CLI, a model in your local vault, and an understanding of the core workflow.</p>"},{"location":"getting-started/#where-to-go","title":"Where to Go","text":"Page Description Installation Clone the repository, install dependencies with Poetry, and verify the CLI Tutorial: First Model Search HuggingFace, download a model, inspect your vault, and export paths for KITT"},{"location":"getting-started/#prerequisites-at-a-glance","title":"Prerequisites at a Glance","text":"Requirement Minimum Version Python 3.10+ Poetry 1.7+ git any recent version <p>Note</p> <p>The CLI does not require Docker. If you want to run DEVON as a containerized REST API, see the Docker Deployment guide.</p>"},{"location":"getting-started/first-model/","title":"Tutorial: Your First Model","text":"<p>This tutorial walks you through the core DEVON workflow: search for a model, inspect it, download it, and export the path for KITT.</p> <p>Prerequisites</p> <p>Complete the Installation guide first. You should be able to run <code>devon --version</code> successfully.</p>"},{"location":"getting-started/first-model/#1-search-for-models","title":"1. Search for Models","text":"<p>Use a free-text query or structured filters to find models.</p> <pre><code>devon search \"llama 3\"\n</code></pre> <p>DEVON queries HuggingFace and displays results in a table with name, provider, parameter count, size, and download count. Add filters to narrow results:</p> <pre><code>devon search --provider qwen --params 30b\n</code></pre> <pre><code>devon search --provider meta-llama --params 70b --size \"&lt;150gb\" --license apache-2.0\n</code></pre> <p>Tip</p> <p>Use <code>--limit</code> to control how many results are shown. The default is 20.</p>"},{"location":"getting-started/first-model/#2-get-model-details","title":"2. Get Model Details","text":"<p>Pull up full metadata for a model before downloading:</p> <pre><code>devon info Qwen/Qwen2.5-32B-Instruct\n</code></pre> <p>This shows parameter count, total size, file list, license, tags, and dates.</p>"},{"location":"getting-started/first-model/#3-download-a-model","title":"3. Download a Model","text":"<p>Download by model ID:</p> <pre><code>devon download Qwen/Qwen2.5-32B-Instruct\n</code></pre> <p>Or by full HuggingFace URL -- DEVON auto-detects the source:</p> <pre><code>devon download https://huggingface.co/Qwen/Qwen2.5-32B-Instruct\n</code></pre> <p>Note</p> <p>Downloads resume automatically if interrupted. Run the same command again and DEVON picks up where it left off.</p> <p>To force a fresh re-download:</p> <pre><code>devon download Qwen/Qwen2.5-32B-Instruct --force\n</code></pre>"},{"location":"getting-started/first-model/#4-verify-the-download","title":"4. Verify the Download","text":"<p>List all models in your local vault:</p> <pre><code>devon list\n</code></pre> <p>You should see a table with your newly downloaded model, its source, size, and date.</p>"},{"location":"getting-started/first-model/#5-check-storage-usage","title":"5. Check Storage Usage","text":"<pre><code>devon status\n</code></pre> <p>This shows total model count, storage consumed, and vault location. If you have configured a <code>max_size_gb</code> limit, remaining capacity is shown as well.</p>"},{"location":"getting-started/first-model/#6-export-for-kitt","title":"6. Export for KITT","text":"<p>Export downloaded model paths in a format KITT can consume:</p> <pre><code>devon export --format kitt -o models.txt\n</code></pre> <p>Then pass the file to KITT:</p> <pre><code>kitt run --model-list models.txt --engine vllm --suite standard\n</code></pre> <p>Tip</p> <p>Use <code>--format json</code> for structured output suitable for scripts or other tooling.</p>"},{"location":"getting-started/first-model/#recap","title":"Recap","text":"Step Command Purpose Search <code>devon search</code> Find models on HuggingFace Inspect <code>devon info</code> View detailed model metadata Download <code>devon download</code> Pull model weights to local storage List <code>devon list</code> See what is in your vault Status <code>devon status</code> Check disk usage Export <code>devon export</code> Produce paths for KITT or other tools"},{"location":"getting-started/first-model/#next-steps","title":"Next Steps","text":"<ul> <li>Advanced search filters: Searching Models</li> <li>Vault management: Managing Models</li> <li>Custom configuration: Configuration</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide covers cloning DEVON, installing dependencies, activating the virtual environment, and verifying the CLI.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"Requirement Minimum Version Check Python 3.10+ <code>python3 --version</code> Poetry 1.7+ <code>poetry --version</code> git any recent version <code>git --version</code> <p>Tip</p> <p>If you don't have Poetry yet, install it with the official installer: <code>curl -sSL https://install.python-poetry.org | python3 -</code></p>"},{"location":"getting-started/installation/#clone-and-install","title":"Clone and Install","text":"<pre><code>git clone https://github.com/kirizan/devon.git\ncd devon\npoetry install\n</code></pre> <p><code>poetry install</code> creates a virtual environment, resolves all dependencies, and installs the <code>devon</code> CLI entry point inside that environment.</p>"},{"location":"getting-started/installation/#activate-the-environment","title":"Activate the Environment","text":"<p>After installation you need to activate the Poetry-managed virtual environment so your shell can find the <code>devon</code> command.</p>"},{"location":"getting-started/installation/#option-1-activate-the-virtual-environment","title":"Option 1 -- Activate the virtual environment","text":"Bash / ZshFish <pre><code>eval $(poetry env activate)\n</code></pre> <pre><code>eval (poetry env activate)\n</code></pre> <p>Once activated, the <code>devon</code> command is available directly:</p> <pre><code>devon --version\ndevon search \"llama\"\n</code></pre> <p>To deactivate when you are done:</p> <pre><code>deactivate\n</code></pre>"},{"location":"getting-started/installation/#option-2-use-poetry-run","title":"Option 2 -- Use <code>poetry run</code>","text":"<p>Prefix every command with <code>poetry run</code> -- works in any shell, no activation needed:</p> <pre><code>poetry run devon --version\npoetry run devon search \"llama\"\n</code></pre>"},{"location":"getting-started/installation/#verify-the-installation","title":"Verify the Installation","text":"<pre><code>devon --version\n</code></pre> <p>You should see output like:</p> <pre><code>devon, version 0.1.0\n</code></pre> <p>If the command is not found, make sure you have activated the virtual environment (Option 1) or are using <code>poetry run</code> (Option 2).</p>"},{"location":"getting-started/installation/#api-extras-optional","title":"API Extras (Optional)","text":"<p>To use the REST API server (<code>devon serve</code>), install the optional API dependencies:</p> <pre><code>poetry install --extras api\n</code></pre> <p>This adds FastAPI and Uvicorn. The CLI works without these extras.</p>"},{"location":"getting-started/installation/#docker-optional","title":"Docker (Optional)","text":"<p>DEVON can also run as a containerized REST API. See the Docker Deployment guide for details.</p>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Head to the First Model tutorial to search for a model and download it to your local vault.</p>"},{"location":"guides/","title":"Guides","text":"<p>How-to guides for common tasks with DEVON. Each guide focuses on a specific workflow and provides concrete commands you can copy and run.</p>"},{"location":"guides/#available-guides","title":"Available Guides","text":""},{"location":"guides/#searching-for-models","title":"Searching for Models","text":"<p>Find models on HuggingFace using keyword search and filters for provider, parameter count, file size, format, task type, and license.</p>"},{"location":"guides/#downloading-models","title":"Downloading Models","text":"<p>Download models by URL or model ID, select specific files with include patterns, and manage disk space.</p>"},{"location":"guides/#managing-local-models","title":"Managing Local Models","text":"<p>List, inspect, and remove downloaded models. Monitor storage usage and clean up unused files.</p>"},{"location":"guides/#rest-api","title":"REST API","text":"<p>Start a FastAPI server with <code>devon serve</code> and manage models over HTTP. Covers authentication, endpoint usage, and integration patterns.</p>"},{"location":"guides/#docker-deployment","title":"Docker Deployment","text":"<p>Run DEVON as a containerized API server. Covers building the image, volume mounts, environment variables, and production tips.</p>"},{"location":"guides/#kitt-integration","title":"KITT Integration","text":"<p>Export your local model library for use with KITT, the inference engine testing suite.</p>"},{"location":"guides/#configuration","title":"Configuration","text":"<p>Customize DEVON's behavior with a YAML configuration file. Set storage paths, search defaults, download options, and display preferences.</p> <p>If you are new to DEVON, start with the Getting Started guide first, then return here when you need help with a specific task.</p>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>DEVON reads its configuration from a YAML file. Every setting has a sensible default so the config file is entirely optional.</p>"},{"location":"guides/configuration/#config-file-location","title":"Config File Location","text":"<pre><code>~/.config/devon/config.yaml\n</code></pre> <p>Create the file and its parent directory:</p> <pre><code>mkdir -p ~/.config/devon\n$EDITOR ~/.config/devon/config.yaml\n</code></pre>"},{"location":"guides/configuration/#deep-merge","title":"Deep Merge","text":"<p>DEVON deep-merges your file over built-in defaults. Only specify keys you want to change; omitted keys keep their defaults.</p>"},{"location":"guides/configuration/#full-reference","title":"Full Reference","text":""},{"location":"guides/configuration/#storage","title":"Storage","text":"<pre><code>storage:\n  base_path: ~/.cache/devon/models   # Where models are saved\n  max_size_gb: null                  # null = unlimited\n</code></pre> <p>Set <code>max_size_gb</code> to cap total cache size.</p>"},{"location":"guides/configuration/#download","title":"Download","text":"<pre><code>download:\n  resume: true              # Resume interrupted downloads\n  verify_checksums: true    # Verify file integrity after download\n</code></pre>"},{"location":"guides/configuration/#sources","title":"Sources","text":"<pre><code>sources:\n  default: huggingface      # Source used when --source is omitted\n  enabled:\n    - huggingface\n</code></pre>"},{"location":"guides/configuration/#search","title":"Search","text":"<pre><code>search:\n  default_limit: 20         # Number of results from devon search\n  sort_by: downloads        # Sort order for search results\n</code></pre>"},{"location":"guides/configuration/#display","title":"Display","text":"<pre><code>display:\n  color: true               # Enable Rich color output\n</code></pre> <p>Set to <code>false</code> when piping output to files or other tools.</p>"},{"location":"guides/configuration/#common-examples","title":"Common Examples","text":""},{"location":"guides/configuration/#custom-storage-directory","title":"Custom storage directory","text":"<pre><code>storage:\n  base_path: /mnt/nvme/devon/models\n</code></pre>"},{"location":"guides/configuration/#cap-storage-at-500-gb","title":"Cap storage at 500 GB","text":"<pre><code>storage:\n  max_size_gb: 500\n</code></pre>"},{"location":"guides/configuration/#return-50-search-results-by-default","title":"Return 50 search results by default","text":"<pre><code>search:\n  default_limit: 50\n</code></pre>"},{"location":"guides/configuration/#disable-color-output","title":"Disable color output","text":"<pre><code>display:\n  color: false\n</code></pre>"},{"location":"guides/configuration/#multiple-overrides-in-one-file","title":"Multiple overrides in one file","text":"<pre><code>storage:\n  base_path: /data/llm-models\n  max_size_gb: 1000\nsearch:\n  default_limit: 50\ndisplay:\n  color: false\n</code></pre>"},{"location":"guides/docker/","title":"Docker Deployment","text":"<p>DEVON ships with a Dockerfile and docker-compose.yml for running the REST API as a container. This is the recommended approach when you want KITT or other remote clients to manage models over HTTP.</p>"},{"location":"guides/docker/#quick-start","title":"Quick Start","text":"<pre><code>docker compose up -d\ncurl http://localhost:8000/health\n</code></pre> <p>That's it. Models are stored in a Docker named volume (<code>devon-data</code>) by default.</p>"},{"location":"guides/docker/#container-layout","title":"Container Layout","text":"<p>The container maps everything under a single <code>/data</code> directory:</p> <pre><code>/data/\n\u251c\u2500\u2500 models/       # Downloaded model files\n\u251c\u2500\u2500 index.json    # Storage index\n\u2514\u2500\u2500 config.yaml   # Configuration (optional)\n</code></pre> <p>Mount a single host path to cover all three:</p> <pre><code>docker compose up -d  # uses named volume by default\n# or\nDEVON_DATA_PATH=/mnt/models docker compose up -d  # uses host path\n</code></pre>"},{"location":"guides/docker/#environment-variables","title":"Environment Variables","text":"Variable Default Description <code>DEVON_PORT</code> <code>8000</code> Host port mapped to the container <code>DEVON_DATA_PATH</code> <code>devon-data</code> (named volume) Host path or named volume for <code>/data</code> <code>DEVON_API_KEY</code> (empty) Bearer token for API auth. Empty disables auth <code>HF_TOKEN</code> (empty) HuggingFace token for gated model access <p>Set variables in a <code>.env</code> file next to <code>docker-compose.yml</code> or export them in your shell.</p>"},{"location":"guides/docker/#example-env","title":"Example <code>.env</code>","text":"<pre><code>DEVON_PORT=9000\nDEVON_DATA_PATH=/mnt/nvme/devon\nDEVON_API_KEY=my-secret-token\nHF_TOKEN=hf_abc123\n</code></pre>"},{"location":"guides/docker/#building-the-image","title":"Building the Image","text":"<p>The Dockerfile uses a multi-stage build:</p> <ol> <li>Builder stage \u2014 installs Poetry, resolves dependencies with <code>--extras api</code>,    and creates an in-project virtualenv.</li> <li>Runtime stage \u2014 copies only the virtualenv and source code into a clean    <code>python:3.12-slim</code> image. Runs as a non-root <code>devon</code> user.</li> </ol> <p>Build manually:</p> <pre><code>docker build -t devon .\n</code></pre> <p>Run manually (without Compose):</p> <pre><code>docker run -d \\\n  --name devon \\\n  -p 8000:8000 \\\n  -v /mnt/models:/data \\\n  -e DEVON_API_KEY=secret \\\n  -e HF_TOKEN=hf_abc123 \\\n  devon\n</code></pre>"},{"location":"guides/docker/#health-check","title":"Health Check","text":"<p>The container includes a built-in Docker healthcheck that hits <code>http://localhost:8000/health</code> every 30 seconds. Check container health:</p> <pre><code>docker inspect --format='{{.State.Health.Status}}' devon\n</code></pre>"},{"location":"guides/docker/#using-your-existing-models","title":"Using Your Existing Models","text":"<p>If you already have models downloaded on the host, mount their parent directory as <code>/data</code>:</p> <pre><code>DEVON_DATA_PATH=/home/user/.cache/devon docker compose up -d\n</code></pre> <p>The container reads the existing <code>index.json</code> and serves models immediately.</p>"},{"location":"guides/docker/#stopping","title":"Stopping","text":"<pre><code>docker compose down       # stop and remove container (data volume preserved)\ndocker compose down -v    # stop and remove container AND named volume\n</code></pre>"},{"location":"guides/docker/#production-tips","title":"Production Tips","text":"<ul> <li>Single worker \u2014 the default runs one Uvicorn worker. This avoids   race conditions on the JSON index. Do not increase worker count without   external write coordination.</li> <li>Set <code>DEVON_API_KEY</code> \u2014 in production, always set an API key to prevent   unauthorized access.</li> <li>Use host path mounts for persistence \u2014 named volumes work but host   paths make backups and migration easier.</li> <li>Set <code>HF_TOKEN</code> \u2014 required for downloading gated models (Llama, etc.).</li> </ul>"},{"location":"guides/docker/#further-reading","title":"Further Reading","text":"<ul> <li>REST API Guide -- endpoint usage and examples</li> <li>REST API Reference -- full request/response schemas</li> <li>Configuration -- YAML config options</li> </ul>"},{"location":"guides/downloading/","title":"Downloading Models","text":"<p>DEVON downloads model files from HuggingFace and stores them in a local cache organized by source and model ID.</p>"},{"location":"guides/downloading/#download-by-url","title":"Download by URL","text":"<p>Pass a HuggingFace URL directly. DEVON auto-detects the source and extracts the model ID:</p> <pre><code>devon download https://huggingface.co/Qwen/Qwen2.5-32B-Instruct\ndevon download https://hf.co/meta-llama/Llama-3.3-70B-Instruct\n</code></pre> <p>Both <code>huggingface.co</code> and <code>hf.co</code> URLs are recognized automatically.</p>"},{"location":"guides/downloading/#download-by-model-id","title":"Download by Model ID","text":"<p>Provide the <code>author/model-name</code> identifier with the <code>--source</code> flag:</p> <pre><code>devon download Qwen/Qwen2.5-32B-Instruct --source huggingface\ndevon download meta-llama/Llama-3.3-70B-Instruct --source huggingface\n</code></pre> <p>When downloading by URL the source is detected from the hostname, so <code>--source</code> is not required.</p>"},{"location":"guides/downloading/#partial-downloads-with-include-patterns","title":"Partial Downloads with Include Patterns","text":"<p>Large repositories often contain multiple quantization variants. Use <code>--include</code> to download only the files you need. The flag accepts glob patterns and can be specified multiple times:</p> <pre><code>devon download Qwen/Qwen2.5-32B-Instruct --include '*Q4_K_M*'\ndevon download Qwen/Qwen2.5-32B-Instruct --include '*Q4_K_M*' --include '*Q5_K_M*'\ndevon download Qwen/Qwen2.5-32B-Instruct --include '*.gguf'\n</code></pre>"},{"location":"guides/downloading/#force-re-download","title":"Force Re-download","text":"<p>If the model already exists locally, DEVON skips it. Pass <code>--force</code> to download everything again:</p> <pre><code>devon download Qwen/Qwen2.5-32B-Instruct --force\n</code></pre>"},{"location":"guides/downloading/#skip-confirmation","title":"Skip Confirmation","text":"<p>By default DEVON shows the download size and asks for confirmation before starting. Use <code>--yes</code> to skip the prompt:</p> <pre><code>devon download Qwen/Qwen2.5-32B-Instruct --yes\n</code></pre>"},{"location":"guides/downloading/#resuming-interrupted-downloads","title":"Resuming Interrupted Downloads","text":"<p>Interrupted downloads resume automatically. If your connection drops or you stop the process, simply run the same command again and DEVON picks up where it left off.</p>"},{"location":"guides/downloading/#disk-space-checking","title":"Disk Space Checking","text":"<p>Before starting a download, DEVON checks that your disk has enough free space to hold the model files. If space is insufficient the download is aborted with a clear error message showing the required and available amounts.</p>"},{"location":"guides/downloading/#storage-location","title":"Storage Location","text":"<p>Downloaded models are stored under the configured base path, organized by source and model ID:</p> <pre><code>~/.cache/devon/models/huggingface/Author/Model/\n</code></pre> <p>For example:</p> <pre><code>~/.cache/devon/models/huggingface/Qwen/Qwen2.5-32B-Instruct/\n~/.cache/devon/models/huggingface/meta-llama/Llama-3.3-70B-Instruct/\n</code></pre> <p>You can change the base path in your configuration file.</p>"},{"location":"guides/kitt-integration/","title":"KITT Integration","text":"<p>DEVON and KITT are companion tools. DEVON manages the models. KITT tests them. Together they form a workflow for downloading models and running inference benchmarks.</p>"},{"location":"guides/kitt-integration/#overview","title":"Overview","text":"<p>KITT is an inference engine testing suite that measures model performance across different serving backends. DEVON's export command produces output in formats that KITT can consume directly.</p>"},{"location":"guides/kitt-integration/#exporting-for-kitt","title":"Exporting for KITT","text":"<p>Generate a text file listing local model paths, one per line:</p> <pre><code>devon export --format kitt -o models.txt\n</code></pre> <p>The resulting <code>models.txt</code> file contains absolute paths to each downloaded model directory, ready for KITT to read.</p>"},{"location":"guides/kitt-integration/#exporting-as-json","title":"Exporting as JSON","text":"<p>For programmatic consumption, export the full model index as JSON:</p> <pre><code>devon export --format json -o models.json\n</code></pre> <p>The JSON output includes model IDs, sources, file sizes, download dates, and local paths.</p>"},{"location":"guides/kitt-integration/#using-the-export-with-kitt","title":"Using the Export with KITT","text":"<p>Pass the exported file to KITT's <code>--model-list</code> flag along with your desired engine and test suite:</p> <pre><code>kitt run --model-list models.txt --engine vllm --suite standard\n</code></pre> <p>KITT reads each path from the file and runs the specified test suite against every model in sequence.</p>"},{"location":"guides/kitt-integration/#full-workflow-example","title":"Full Workflow Example","text":"<p>A typical workflow from discovery to testing:</p> <pre><code># 1. Search for candidate models\ndevon search \"qwen instruct\" --params 7b --format gguf\n\n# 2. Download the ones you want\ndevon download Qwen/Qwen2.5-7B-Instruct\n\n# 3. Export paths for KITT\ndevon export --format kitt -o models.txt\n\n# 4. Run inference tests\nkitt run --model-list models.txt --engine vllm --suite standard\n</code></pre> <p>This pattern scales to any number of models. Download as many as you need, export once, and KITT tests them all.</p>"},{"location":"guides/kitt-integration/#remote-integration-via-rest-api","title":"Remote Integration via REST API","text":"<p>When DEVON runs as a containerized API server, KITT (or any client) can manage models over HTTP without requiring DEVON to be installed locally:</p> <pre><code># Search for models\ncurl \"http://devon-host:8000/api/v1/search?provider=qwen&amp;limit=5\"\n\n# Download a model\ncurl -X POST http://devon-host:8000/api/v1/downloads \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model_id\": \"Qwen/Qwen2.5-7B-Instruct\"}'\n\n# Export model paths\ncurl -X POST http://devon-host:8000/api/v1/export \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"format\": \"kitt\"}'\n</code></pre> <p>See the REST API guide and Docker Deployment guide for setup details.</p>"},{"location":"guides/kitt-integration/#further-reading","title":"Further Reading","text":"<ul> <li>KITT documentation</li> <li>Searching for models</li> <li>Downloading models</li> <li>Managing local models</li> <li>REST API</li> <li>Docker Deployment</li> </ul>"},{"location":"guides/managing/","title":"Managing Local Models","text":"<p>Once you have downloaded models with DEVON, a set of commands lets you list, inspect, and clean up your local collection.</p>"},{"location":"guides/managing/#listing-models","title":"Listing Models","text":"<p>Show all locally downloaded models:</p> <pre><code>devon list\n</code></pre> <p>Filter by source:</p> <pre><code>devon list --source huggingface\n</code></pre>"},{"location":"guides/managing/#model-details","title":"Model Details","text":"<p>Fetch detailed information about a model. DEVON queries HuggingFace for live metadata and merges it with local storage information:</p> <pre><code>devon info Qwen/Qwen2.5-32B-Instruct\ndevon info meta-llama/Llama-3.3-70B-Instruct\n</code></pre>"},{"location":"guides/managing/#storage-status","title":"Storage Status","text":"<p>Get a summary of how much disk space your model collection uses:</p> <pre><code>devon status\n</code></pre> <p>The report shows total size, breakdown by source, and model count.</p>"},{"location":"guides/managing/#removing-a-model","title":"Removing a Model","text":"<p>Delete a specific model from local storage:</p> <pre><code>devon remove Qwen/Qwen2.5-32B-Instruct\n</code></pre> <p>Skip the confirmation prompt with <code>--yes</code>:</p> <pre><code>devon remove Qwen/Qwen2.5-32B-Instruct --yes\n</code></pre>"},{"location":"guides/managing/#cleaning-up","title":"Cleaning Up","text":"<p>The <code>clean</code> command removes models based on usage criteria.</p> <p>Remove unused models older than a threshold:</p> <pre><code>devon clean --unused --days 30\n</code></pre> <p>Preview what would be removed without deleting anything:</p> <pre><code>devon clean --dry-run\ndevon clean --all --dry-run\ndevon clean --unused --days 30 --dry-run\n</code></pre> <p>Remove all cached models:</p> <pre><code>devon clean --all\n</code></pre>"},{"location":"guides/managing/#storage-directory-structure","title":"Storage Directory Structure","text":"<p>DEVON organizes downloaded files under the configured base path:</p> <pre><code>~/.cache/devon/\n\u251c\u2500\u2500 models/\n\u2502   \u2514\u2500\u2500 huggingface/\n\u2502       \u251c\u2500\u2500 Qwen/Qwen2.5-32B-Instruct/\n\u2502       \u2514\u2500\u2500 meta-llama/Llama-3.3-70B-Instruct/\n\u2514\u2500\u2500 index.json\n</code></pre> <ul> <li>models/ contains one directory per source, with subdirectories for   each <code>author/model-name</code> pair.</li> <li>index.json tracks metadata for every downloaded model including   source, model ID, download date, and file sizes. DEVON uses this index   for fast lookups without scanning the filesystem.</li> </ul> <p>You can change the storage base path in your configuration file.</p>"},{"location":"guides/rest-api/","title":"REST API","text":"<p>DEVON includes a FastAPI-based REST API server that exposes every core capability over HTTP. Use it when you need to manage models remotely -- for example, from KITT or a CI pipeline -- without installing DEVON on the client machine.</p>"},{"location":"guides/rest-api/#prerequisites","title":"Prerequisites","text":"<p>Install the optional API dependencies:</p> <pre><code>poetry install --extras api\n</code></pre> <p>This adds FastAPI and Uvicorn. The standard CLI continues to work without these extras.</p>"},{"location":"guides/rest-api/#starting-the-server","title":"Starting the Server","text":"<pre><code>devon serve                             # http://127.0.0.1:8000\ndevon serve --host 0.0.0.0 --port 9000 # bind to all interfaces\ndevon serve --reload                    # auto-reload on code changes (dev)\n</code></pre> <p>Tip</p> <p>For containerized deployments, see the Docker Deployment guide instead of running <code>devon serve</code> directly.</p>"},{"location":"guides/rest-api/#authentication","title":"Authentication","text":"<p>Authentication is optional. Set the <code>DEVON_API_KEY</code> environment variable to enable bearer token auth on all <code>/api/v1/*</code> endpoints. The <code>/health</code> endpoint is always unauthenticated.</p> <pre><code>DEVON_API_KEY=my-secret devon serve\n</code></pre> <p>Clients pass the token in the <code>Authorization</code> header:</p> <pre><code>curl -H \"Authorization: Bearer my-secret\" http://localhost:8000/api/v1/models\n</code></pre> <p>When <code>DEVON_API_KEY</code> is unset or empty, all requests are allowed without a token.</p>"},{"location":"guides/rest-api/#endpoint-overview","title":"Endpoint Overview","text":"Method Path Description GET <code>/health</code> Health check (no auth) GET <code>/api/v1/search</code> Search remote models GET <code>/api/v1/models</code> List local models GET <code>/api/v1/models/{source}/{model_id}</code> Model info (local + remote) DELETE <code>/api/v1/models/{source}/{model_id}</code> Remove a model POST <code>/api/v1/downloads</code> Download a model GET <code>/api/v1/status</code> Storage stats POST <code>/api/v1/clean</code> Clean unused models POST <code>/api/v1/export</code> Export model list <p>See the REST API Reference for full request and response schemas.</p>"},{"location":"guides/rest-api/#usage-examples","title":"Usage Examples","text":""},{"location":"guides/rest-api/#health-check","title":"Health check","text":"<pre><code>curl http://localhost:8000/health\n</code></pre> <pre><code>{\"status\": \"ok\", \"version\": \"1.0.0\"}\n</code></pre>"},{"location":"guides/rest-api/#search-for-models","title":"Search for models","text":"<p>Query parameters mirror the CLI's <code>--provider</code>, <code>--params</code>, <code>--size</code>, <code>--format</code>, <code>--task</code>, <code>--license</code>, and <code>--limit</code> flags:</p> <pre><code>curl \"http://localhost:8000/api/v1/search?provider=qwen&amp;params=7b&amp;limit=3\"\n</code></pre>"},{"location":"guides/rest-api/#list-local-models","title":"List local models","text":"<pre><code>curl http://localhost:8000/api/v1/models\n</code></pre> <p>Filter by source:</p> <pre><code>curl \"http://localhost:8000/api/v1/models?source=huggingface\"\n</code></pre>"},{"location":"guides/rest-api/#get-model-info","title":"Get model info","text":"<p>Returns both local storage info and remote metadata:</p> <pre><code>curl http://localhost:8000/api/v1/models/huggingface/Qwen/Qwen2.5-7B-Instruct\n</code></pre>"},{"location":"guides/rest-api/#download-a-model","title":"Download a model","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/downloads \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"model_id\": \"Qwen/Qwen2.5-7B-Instruct\"}'\n</code></pre> <p>Long-running request</p> <p>Downloads run synchronously in the request thread. Set a long client timeout (e.g., 30 minutes) for large models.</p> <p>Optional fields in the request body:</p> Field Type Default Description <code>model_id</code> string (required) Model identifier <code>source</code> string <code>\"huggingface\"</code> Source plugin name <code>force</code> bool <code>false</code> Re-download even if already present <code>include_patterns</code> list[string] <code>null</code> Glob patterns to filter files"},{"location":"guides/rest-api/#delete-a-model","title":"Delete a model","text":"<pre><code>curl -X DELETE http://localhost:8000/api/v1/models/huggingface/Qwen/Qwen2.5-7B-Instruct\n</code></pre>"},{"location":"guides/rest-api/#storage-status","title":"Storage status","text":"<pre><code>curl http://localhost:8000/api/v1/status\n</code></pre>"},{"location":"guides/rest-api/#clean-unused-models","title":"Clean unused models","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/clean \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"unused\": true, \"days\": 30}'\n</code></pre> <p>Preview without deleting:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/clean \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"unused\": true, \"days\": 30, \"dry_run\": true}'\n</code></pre>"},{"location":"guides/rest-api/#export-model-list","title":"Export model list","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/export \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"format\": \"kitt\"}'\n</code></pre>"},{"location":"guides/rest-api/#environment-variables","title":"Environment Variables","text":"<p>The API server respects these environment variables:</p> Variable Description <code>DEVON_API_KEY</code> Bearer token for authentication (empty = no auth) <code>DEVON_STORAGE_PATH</code> Override the model storage directory <code>DEVON_CONFIG_PATH</code> Override the config file path <code>HF_TOKEN</code> HuggingFace token for gated model access"},{"location":"guides/rest-api/#limitations","title":"Limitations","text":"<ul> <li>Single worker \u2014 the default runs one Uvicorn worker to avoid race   conditions on JSON index writes. Do not increase worker count without   external write coordination.</li> <li>Synchronous downloads \u2014 model downloads block the request thread.   Background task support may be added in a future release.</li> </ul>"},{"location":"guides/rest-api/#further-reading","title":"Further Reading","text":"<ul> <li>REST API Reference -- full request/response schemas</li> <li>Docker Deployment -- containerized deployment</li> <li>KITT Integration -- using the API with KITT</li> </ul>"},{"location":"guides/searching/","title":"Searching for Models","text":"<p>DEVON searches HuggingFace for models matching your query and filters. Results are displayed in a Rich table showing the model ID, size, download count, and format.</p>"},{"location":"guides/searching/#basic-search","title":"Basic Search","text":"<p>Pass a keyword or phrase to find matching models:</p> <pre><code>devon search \"llama 3\"\ndevon search \"code generation\"\n</code></pre> Example output (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 20 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                      \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 meta-llama/Llama-3.3-70B-Instruct          \u2502    70B \u2502  140 GB  \u2502 safetensors   \u2502      1.2M  \u2502\n\u2502 2 \u2502 meta-llama/Llama-3.1-8B-Instruct           \u2502     8B \u2502   16 GB  \u2502 safetensors   \u2502      985K  \u2502\n\u2502 3 \u2502 meta-llama/Llama-3.1-70B-Instruct          \u2502    70B \u2502  140 GB  \u2502 safetensors   \u2502      742K  \u2502\n\u2502 4 \u2502 bartowski/Meta-Llama-3.1-8B-Instruct-GGUF  \u2502     8B \u2502    5 GB  \u2502 gguf          \u2502      528K  \u2502\n\u2502 5 \u2502 meta-llama/Llama-3.2-3B-Instruct           \u2502     3B \u2502    6 GB  \u2502 safetensors   \u2502      415K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/searching/#filter-reference","title":"Filter Reference","text":"<p>All filters are optional and can be combined freely. When multiple filters are used, they stack with AND logic \u2014 only models matching every filter are returned.</p> Filter Flag Short Accepts Example Provider <code>--provider</code> <code>-p</code> Author/org name <code>--provider qwen</code> Parameters <code>--params</code> Count with <code>b</code> suffix <code>--params 30b</code> Size <code>--size</code> Operator + number + unit <code>--size \"&lt;100gb\"</code> Format <code>--format</code> <code>-f</code> Format name <code>--format gguf</code> Task <code>--task</code> <code>-t</code> Pipeline tag <code>--task text-generation</code> License <code>--license</code> <code>-l</code> SPDX identifier <code>--license apache-2.0</code> Limit <code>--limit</code> Integer <code>--limit 50</code> Source <code>--source</code> Source name <code>--source huggingface</code>"},{"location":"guides/searching/#filters-in-detail","title":"Filters in Detail","text":""},{"location":"guides/searching/#provider-provider-p","title":"Provider (<code>--provider</code>, <code>-p</code>)","text":"<p>Filter by the model author or organization. The match is case-insensitive.</p> <pre><code>devon search --provider qwen\ndevon search -p meta-llama\ndevon search -p microsoft\n</code></pre> Example: <code>devon search --provider qwen --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 5 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                    \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 Qwen/Qwen2.5-72B-Instruct               \u2502    72B \u2502  144 GB  \u2502 safetensors   \u2502      1.8M  \u2502\n\u2502 2 \u2502 Qwen/Qwen2.5-32B-Instruct               \u2502    32B \u2502   64 GB  \u2502 safetensors   \u2502      1.1M  \u2502\n\u2502 3 \u2502 Qwen/Qwen2.5-7B-Instruct                \u2502     7B \u2502   14 GB  \u2502 safetensors   \u2502      892K  \u2502\n\u2502 4 \u2502 Qwen/Qwen2.5-Coder-32B-Instruct         \u2502    32B \u2502   64 GB  \u2502 safetensors   \u2502      654K  \u2502\n\u2502 5 \u2502 Qwen/QwQ-32B                             \u2502    32B \u2502   64 GB  \u2502 safetensors   \u2502      512K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/searching/#parameter-count-params","title":"Parameter Count (<code>--params</code>)","text":"<p>Filter by the number of parameters. Pass a number with a <code>b</code> suffix (e.g., <code>7b</code>, <code>30b</code>, <code>70b</code>). DEVON matches with a \u00b120% tolerance so <code>--params 30b</code> returns models with 24B\u201336B parameters.</p> <pre><code>devon search --params 7b\ndevon search --params 30b\ndevon search --params 70b\n</code></pre> Example: <code>devon search --params 7b --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 5 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                      \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 meta-llama/Llama-3.1-8B-Instruct           \u2502     8B \u2502   16 GB  \u2502 safetensors   \u2502      985K  \u2502\n\u2502 2 \u2502 Qwen/Qwen2.5-7B-Instruct                  \u2502     7B \u2502   14 GB  \u2502 safetensors   \u2502      892K  \u2502\n\u2502 3 \u2502 mistralai/Mistral-7B-Instruct-v0.3         \u2502     7B \u2502   14 GB  \u2502 safetensors   \u2502      612K  \u2502\n\u2502 4 \u2502 google/gemma-2-9b-it                       \u2502     9B \u2502   18 GB  \u2502 safetensors   \u2502      487K  \u2502\n\u2502 5 \u2502 bartowski/Qwen2.5-7B-Instruct-GGUF         \u2502     7B \u2502    5 GB  \u2502 gguf          \u2502      321K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Tolerance</p> <p>The \u00b120% window means <code>--params 30b</code> matches anything from 24B to 36B. This catches models labeled as 32B or 34B that are close to 30B.</p>"},{"location":"guides/searching/#file-size-size","title":"File Size (<code>--size</code>)","text":"<p>Constrain by total model size on disk. The value is an operator followed by a number and unit.</p> <p>Supported operators: <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code></p> <p>Supported units: <code>mb</code>, <code>gb</code>, <code>tb</code> (case-insensitive)</p> <pre><code>devon search --size \"&lt;10gb\"\ndevon search --size \"&lt;=50gb\"\ndevon search --size \"&gt;100gb\"\ndevon search --size \"&gt;=500mb\"\n</code></pre> <p>Quote the value</p> <p>Shell metacharacters <code>&lt;</code> and <code>&gt;</code> require quoting. Always wrap the size value in quotes: <code>--size \"&lt;100gb\"</code>.</p> Example: <code>devon search --size \\\"&lt;10gb\\\" --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 5 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                        \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 bartowski/Meta-Llama-3.1-8B-Instruct-GGUF    \u2502     8B \u2502    5 GB  \u2502 gguf          \u2502      528K  \u2502\n\u2502 2 \u2502 meta-llama/Llama-3.2-3B-Instruct             \u2502     3B \u2502    6 GB  \u2502 safetensors   \u2502      415K  \u2502\n\u2502 3 \u2502 Qwen/Qwen2.5-3B-Instruct                    \u2502     3B \u2502    6 GB  \u2502 safetensors   \u2502      298K  \u2502\n\u2502 4 \u2502 bartowski/Qwen2.5-7B-Instruct-GGUF           \u2502     7B \u2502    5 GB  \u2502 gguf          \u2502      321K  \u2502\n\u2502 5 \u2502 microsoft/Phi-3.5-mini-instruct              \u2502     4B \u2502    8 GB  \u2502 safetensors   \u2502      276K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/searching/#format-format-f","title":"Format (<code>--format</code>, <code>-f</code>)","text":"<p>Filter by model file format. Common values:</p> Format Description <code>gguf</code> Quantized format for llama.cpp and compatible runtimes <code>safetensors</code> Safe, fast tensor serialization (HuggingFace default) <code>pytorch</code> PyTorch <code>.bin</code> checkpoint files <code>onnx</code> ONNX runtime format <pre><code>devon search --format gguf\ndevon search -f safetensors\ndevon search -f onnx\n</code></pre> Example: <code>devon search --format gguf --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 5 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                          \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 bartowski/Meta-Llama-3.3-70B-Instruct-GGUF     \u2502    70B \u2502   42 GB  \u2502 gguf          \u2502      412K  \u2502\n\u2502 2 \u2502 bartowski/Meta-Llama-3.1-8B-Instruct-GGUF      \u2502     8B \u2502    5 GB  \u2502 gguf          \u2502      528K  \u2502\n\u2502 3 \u2502 bartowski/Qwen2.5-32B-Instruct-GGUF            \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      389K  \u2502\n\u2502 4 \u2502 bartowski/Qwen2.5-7B-Instruct-GGUF             \u2502     7B \u2502    5 GB  \u2502 gguf          \u2502      321K  \u2502\n\u2502 5 \u2502 bartowski/Mistral-7B-Instruct-v0.3-GGUF        \u2502     7B \u2502    5 GB  \u2502 gguf          \u2502      198K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/searching/#task-task-t","title":"Task (<code>--task</code>, <code>-t</code>)","text":"<p>Filter by the HuggingFace pipeline tag. This maps to the model's intended use case.</p> <p>Common task values:</p> Task Description <code>text-generation</code> Causal language models (GPT-style) <code>text2text-generation</code> Encoder-decoder models (T5-style) <code>feature-extraction</code> Embedding models <code>text-classification</code> Sentiment, topic, etc. <code>question-answering</code> Extractive QA <code>summarization</code> Text summarization <code>translation</code> Machine translation <pre><code>devon search --task text-generation\ndevon search -t feature-extraction\ndevon search -t text2text-generation\n</code></pre> Example: <code>devon search --task text-generation --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 5 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                      \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 meta-llama/Llama-3.3-70B-Instruct          \u2502    70B \u2502  140 GB  \u2502 safetensors   \u2502      1.2M  \u2502\n\u2502 2 \u2502 Qwen/Qwen2.5-72B-Instruct                  \u2502    72B \u2502  144 GB  \u2502 safetensors   \u2502      1.8M  \u2502\n\u2502 3 \u2502 meta-llama/Llama-3.1-8B-Instruct           \u2502     8B \u2502   16 GB  \u2502 safetensors   \u2502      985K  \u2502\n\u2502 4 \u2502 mistralai/Mistral-7B-Instruct-v0.3         \u2502     7B \u2502   14 GB  \u2502 safetensors   \u2502      612K  \u2502\n\u2502 5 \u2502 google/gemma-2-27b-it                      \u2502    27B \u2502   54 GB  \u2502 safetensors   \u2502      487K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/searching/#license-license-l","title":"License (<code>--license</code>, <code>-l</code>)","text":"<p>Filter by the model license. The match is case-insensitive. Use the SPDX identifier when available.</p> <p>Common license values:</p> License Description <code>apache-2.0</code> Apache License 2.0 <code>mit</code> MIT License <code>llama3.1</code> Meta Llama 3.1 Community License <code>gemma</code> Google Gemma Terms of Use <code>cc-by-4.0</code> Creative Commons Attribution 4.0 <code>cc-by-nc-4.0</code> Creative Commons Attribution Non-Commercial 4.0 <pre><code>devon search --license apache-2.0\ndevon search -l mit\ndevon search -l llama3.1\n</code></pre> Example: <code>devon search --license apache-2.0 --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 5 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                        \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 Qwen/Qwen2.5-72B-Instruct                    \u2502    72B \u2502  144 GB  \u2502 safetensors   \u2502      1.8M  \u2502\n\u2502 2 \u2502 Qwen/Qwen2.5-32B-Instruct                    \u2502    32B \u2502   64 GB  \u2502 safetensors   \u2502      1.1M  \u2502\n\u2502 3 \u2502 Qwen/Qwen2.5-7B-Instruct                    \u2502     7B \u2502   14 GB  \u2502 safetensors   \u2502      892K  \u2502\n\u2502 4 \u2502 mistralai/Mistral-7B-Instruct-v0.3           \u2502     7B \u2502   14 GB  \u2502 safetensors   \u2502      612K  \u2502\n\u2502 5 \u2502 microsoft/Phi-3.5-mini-instruct              \u2502     4B \u2502    8 GB  \u2502 safetensors   \u2502      276K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/searching/#limit-limit","title":"Limit (<code>--limit</code>)","text":"<p>Control the maximum number of results returned. Default is 20.</p> <pre><code>devon search \"llama\" --limit 50\ndevon search \"code\" --limit 5\ndevon search --provider qwen --limit 3\n</code></pre> <p>You can set a permanent default in your configuration file under <code>search.limit</code>.</p>"},{"location":"guides/searching/#source-source","title":"Source (<code>--source</code>)","text":"<p>Select which model source to query. Currently only <code>huggingface</code> is supported (and is the default).</p> <pre><code>devon search \"llama\" --source huggingface\n</code></pre>"},{"location":"guides/searching/#inline-query-parsing","title":"Inline Query Parsing","text":"<p>DEVON's query parser can extract filters directly from the search query without needing explicit flags. This enables a more natural search style.</p> Pattern Detected As Example <code>&lt;number&gt;b</code> Parameter count <code>30b</code> \u2192 <code>--params 30b</code> <code>gguf</code>, <code>safetensors</code>, <code>pytorch</code>, <code>onnx</code> Format <code>gguf</code> \u2192 <code>--format gguf</code> <code>Q4_K_M</code>, <code>Q5_K_M</code>, <code>Q8_0</code>, <code>fp16</code>, <code>bf16</code>, <code>int8</code>, <code>int4</code> Quantization <code>Q4_K_M</code> \u2192 quant filter <pre><code># These two are equivalent:\ndevon search \"qwen 30b gguf\"\ndevon search \"qwen\" --params 30b --format gguf\n\n# These two are equivalent:\ndevon search \"llama 7b safetensors\"\ndevon search \"llama\" --params 7b --format safetensors\n</code></pre> Example: <code>devon search \\\"qwen 30b gguf\\\" --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 5 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                        \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 bartowski/Qwen2.5-32B-Instruct-GGUF          \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      389K  \u2502\n\u2502 2 \u2502 Qwen/Qwen2.5-32B-Instruct-GGUF              \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      245K  \u2502\n\u2502 3 \u2502 bartowski/QwQ-32B-GGUF                       \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      178K  \u2502\n\u2502 4 \u2502 bartowski/Qwen2.5-Coder-32B-Instruct-GGUF   \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      156K  \u2502\n\u2502 5 \u2502 mradermacher/Qwen2.5-32B-Instruct-GGUF      \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502       98K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/searching/#combining-filters","title":"Combining Filters","text":"<p>Filters stack with AND logic. Only models matching every filter are returned. Combine as many as needed in a single command.</p> <pre><code># Qwen models around 30B in GGUF format\ndevon search --provider qwen --params 30b --format gguf\n\n# Llama instruct models under 50 GB in safetensors\ndevon search \"instruct\" --provider meta-llama --size \"&lt;50gb\" --format safetensors\n\n# Apache-licensed text-generation models (first 50 results)\ndevon search --task text-generation --license apache-2.0 --limit 50\n\n# Small GGUF models for local testing\ndevon search --format gguf --size \"&lt;5gb\" --params 7b\n\n# Everything from Microsoft under 20 GB\ndevon search --provider microsoft --size \"&lt;20gb\"\n</code></pre> Example: <code>devon search --provider qwen --params 30b --format gguf --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 5 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                        \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 bartowski/Qwen2.5-32B-Instruct-GGUF          \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      389K  \u2502\n\u2502 2 \u2502 Qwen/Qwen2.5-32B-Instruct-GGUF              \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      245K  \u2502\n\u2502 3 \u2502 bartowski/Qwen2.5-Coder-32B-Instruct-GGUF   \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      156K  \u2502\n\u2502 4 \u2502 bartowski/QwQ-32B-GGUF                       \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502      178K  \u2502\n\u2502 5 \u2502 mradermacher/Qwen2.5-32B-Instruct-GGUF      \u2502    32B \u2502   20 GB  \u2502 gguf          \u2502       98K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Example: <code>devon search \\\"instruct\\\" --provider meta-llama --size \\\"&lt;50gb\\\" --format safetensors --limit 5</code> (generated 2026-02-12) <pre><code>Searching huggingface...\n\nFound 3 models:\n\n\u250f\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 # \u2503 Model                                      \u2503 Params \u2503     Size \u2503 Format        \u2503  Downloads \u2503\n\u2521\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 1 \u2502 meta-llama/Llama-3.1-8B-Instruct           \u2502     8B \u2502   16 GB  \u2502 safetensors   \u2502      985K  \u2502\n\u2502 2 \u2502 meta-llama/Llama-3.2-3B-Instruct           \u2502     3B \u2502    6 GB  \u2502 safetensors   \u2502      415K  \u2502\n\u2502 3 \u2502 meta-llama/Llama-3.2-1B-Instruct           \u2502     1B \u2502    2 GB  \u2502 safetensors   \u2502      312K  \u2502\n\u2514\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/searching/#search-results-display","title":"Search Results Display","text":"<p>Results appear in a Rich table with these columns:</p> Column Description # Row number Model Full model ID (<code>author/name</code>) Params Parameter count in billions Size Total size on disk (formatted) Format File format(s), up to two shown Downloads Total download count (abbreviated) <p>Models are sorted by download count (most popular first) unless you change <code>search.sort_by</code> in your configuration file.</p> <p>No results?</p> <p>If a search returns no models, try relaxing your filters. Remove the most restrictive one first (often <code>--params</code> or <code>--size</code>) and broaden from there.</p>"},{"location":"reference/","title":"Reference","text":"<p>Technical reference material for DEVON. These pages document the exact interfaces, schemas, and data structures that make up the tool.</p> <p>Use this section when you need precise details about a command flag, a configuration key, or the shape of stored data.</p>"},{"location":"reference/#sections","title":"Sections","text":"<ul> <li> <p>CLI Reference -- Every command, option, and argument   exposed by the <code>devon</code> CLI.</p> </li> <li> <p>REST API Reference -- Endpoint paths, request/response   schemas, authentication, and error codes for the DEVON REST API.</p> </li> <li> <p>Configuration Schema -- All keys accepted in   <code>~/.config/devon/config.yaml</code>, their types, and default values.</p> </li> <li> <p>Model Metadata -- Fields in the <code>ModelMetadata</code>   dataclass returned by source plugins and stored in the local index.</p> </li> <li> <p>Storage Index -- Format of the JSON index file,   key conventions, and <code>ModelStorage</code> class methods.</p> </li> </ul>"},{"location":"reference/configuration/","title":"Configuration Schema","text":"<p>DEVON reads its configuration from a YAML file at:</p> <pre><code>~/.config/devon/config.yaml\n</code></pre> <p>If the file does not exist, DEVON uses built-in defaults for every setting.</p>"},{"location":"reference/configuration/#how-configuration-is-loaded","title":"How Configuration Is Loaded","text":"<p>The <code>Settings</code> class in <code>devon.config.settings</code> handles configuration:</p> <ol> <li>A <code>DEFAULT_CONFIG</code> dictionary defines every key and its default value.</li> <li>If the YAML file exists, it is loaded and deep-merged over the    defaults -- user values override defaults while unset keys keep their    default.</li> <li>Values are accessed with dot-notation through <code>settings.get()</code>:</li> </ol> <pre><code>from devon.config.settings import Settings\n\nsettings = Settings()\nbase = settings.get(\"storage.base_path\")   # \"~/.cache/devon/models\"\nlimit = settings.get(\"search.default_limit\")  # 20\n</code></pre> <p>Convenience properties are also available:</p> Property Equivalent <code>get()</code> call <code>settings.storage_path</code> <code>settings.get(\"storage.base_path\")</code> <code>settings.default_source</code> <code>settings.get(\"sources.default\")</code> <code>settings.search_limit</code> <code>settings.get(\"search.default_limit\")</code>"},{"location":"reference/configuration/#full-schema","title":"Full Schema","text":"Section Key Type Default Description <code>storage</code> <code>base_path</code> string <code>~/.cache/devon/models</code> Root directory for downloaded models <code>storage</code> <code>max_size_gb</code> int or null <code>null</code> Maximum total storage in GB. <code>null</code> means unlimited <code>download</code> <code>resume</code> bool <code>true</code> Resume interrupted downloads instead of restarting <code>download</code> <code>verify_checksums</code> bool <code>true</code> Verify file checksums after download completes <code>sources</code> <code>default</code> string <code>huggingface</code> Source plugin used when <code>--source</code> is not specified <code>sources</code> <code>enabled</code> list[string] <code>[huggingface]</code> Source plugins that are active <code>search</code> <code>default_limit</code> int <code>20</code> Number of results returned by <code>devon search</code> <code>search</code> <code>sort_by</code> string <code>downloads</code> Default sort order: <code>downloads</code>, <code>likes</code>, or <code>last_modified</code> <code>display</code> <code>color</code> bool <code>true</code> Enable colored output via Rich"},{"location":"reference/configuration/#example-file","title":"Example File","text":"<pre><code>storage:\n  base_path: ~/models\n  max_size_gb: 100\n\ndownload:\n  resume: true\n  verify_checksums: true\n\nsources:\n  default: huggingface\n  enabled:\n    - huggingface\n\nsearch:\n  default_limit: 50\n  sort_by: likes\n\ndisplay:\n  color: true\n</code></pre>"},{"location":"reference/configuration/#notes","title":"Notes","text":"<ul> <li>Paths containing <code>~</code> are expanded to the user's home directory at load   time.</li> <li>Unknown keys are silently ignored, so older config files remain forward   compatible.</li> <li>The deep-merge strategy means you only need to include the keys you want   to change; everything else falls back to the default.</li> </ul>"},{"location":"reference/model-metadata/","title":"Model Metadata","text":"<p>The <code>ModelMetadata</code> dataclass is the central data structure DEVON uses to represent a model. It is returned by source plugins, displayed by CLI commands, and persisted in the storage index.</p>"},{"location":"reference/model-metadata/#location","title":"Location","text":"<pre><code>devon.models.model_info.ModelMetadata\n</code></pre>"},{"location":"reference/model-metadata/#fields","title":"Fields","text":"Field Type Description <code>source</code> <code>str</code> Source identifier (e.g., <code>\"huggingface\"</code>) <code>model_id</code> <code>str</code> Full model ID (e.g., <code>\"Qwen/Qwen2.5-32B\"</code>) <code>model_name</code> <code>str</code> Human-readable display name <code>author</code> <code>str</code> Model author or organization <code>total_size_bytes</code> <code>int</code> Total size of all model files in bytes <code>file_count</code> <code>int</code> Number of files in the model repository <code>parameter_count</code> <code>Optional[int]</code> Parameter count (in billions). <code>None</code> if unknown <code>architecture</code> <code>Optional[str]</code> Model architecture (e.g., <code>llama</code>, <code>qwen</code>, <code>mistral</code>) <code>format</code> <code>List[str]</code> Available formats: <code>gguf</code>, <code>safetensors</code>, <code>pytorch</code> <code>quantization</code> <code>Optional[str]</code> Quantization type (e.g., <code>Q4_K_M</code>, <code>Q5_K_M</code>). <code>None</code> for full-precision <code>tags</code> <code>List[str]</code> Tags from the model repository <code>license</code> <code>Optional[str]</code> License identifier (e.g., <code>\"apache-2.0\"</code>, <code>\"mit\"</code>) <code>downloads</code> <code>int</code> Total download count <code>likes</code> <code>int</code> Total like count <code>created_at</code> <code>str</code> ISO 8601 creation timestamp <code>updated_at</code> <code>str</code> ISO 8601 last-modified timestamp <code>web_url</code> <code>str</code> Browser-facing URL for the model page <code>repo_url</code> <code>str</code> Repository URL used for cloning or API access <code>extra</code> <code>Dict[str, Any]</code> Source-specific fields that do not fit the standard schema"},{"location":"reference/model-metadata/#usage","title":"Usage","text":"<p>Source plugins construct <code>ModelMetadata</code> instances in their <code>search()</code> and <code>get_model_info()</code> methods:</p> <pre><code>from devon.models.model_info import ModelMetadata\n\nmeta = ModelMetadata(\n    source=\"huggingface\",\n    model_id=\"Qwen/Qwen2.5-32B-Instruct\",\n    model_name=\"Qwen2.5-32B-Instruct\",\n    author=\"Qwen\",\n    total_size_bytes=67_108_864_000,\n    file_count=12,\n    parameter_count=32,\n    architecture=\"qwen\",\n    format=[\"safetensors\"],\n    quantization=None,\n    tags=[\"text-generation\", \"conversational\"],\n    license=\"apache-2.0\",\n    downloads=150_000,\n    likes=2_400,\n    created_at=\"2025-01-15T10:00:00Z\",\n    updated_at=\"2025-02-01T08:30:00Z\",\n    web_url=\"https://huggingface.co/Qwen/Qwen2.5-32B-Instruct\",\n    repo_url=\"https://huggingface.co/Qwen/Qwen2.5-32B-Instruct\",\n    extra={},\n)\n</code></pre>"},{"location":"reference/model-metadata/#notes","title":"Notes","text":"<ul> <li>The <code>license</code> field may come from HuggingFace as a list; the HuggingFace   source plugin joins multiple values with <code>\", \"</code> before storing.</li> <li>The <code>extra</code> dict allows source plugins to carry additional data without   modifying the shared dataclass.</li> <li>When serialized to the storage index, <code>ModelMetadata</code> is stored inside the   <code>\"metadata\"</code> key of each index entry.</li> </ul>"},{"location":"reference/rest-api/","title":"REST API Reference","text":"<p>Technical reference for every endpoint in the DEVON REST API. For usage examples and getting-started instructions, see the REST API guide.</p>"},{"location":"reference/rest-api/#base-url","title":"Base URL","text":"<pre><code>http://{host}:{port}\n</code></pre> <p>Default: <code>http://127.0.0.1:8000</code></p>"},{"location":"reference/rest-api/#authentication","title":"Authentication","text":"<p>When the <code>DEVON_API_KEY</code> environment variable is set, all <code>/api/v1/*</code> endpoints require a bearer token:</p> <pre><code>Authorization: Bearer {token}\n</code></pre> <p>The <code>/health</code> endpoint never requires authentication.</p> <p>Unauthorized requests receive:</p> <pre><code>{\"detail\": \"Invalid or missing API key\"}\n</code></pre> <p>Status code: <code>401 Unauthorized</code></p>"},{"location":"reference/rest-api/#endpoints","title":"Endpoints","text":""},{"location":"reference/rest-api/#get-health","title":"GET /health","text":"<p>Health check. Always unauthenticated.</p> <p>Response <code>200</code></p> <pre><code>{\n  \"status\": \"ok\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>"},{"location":"reference/rest-api/#get-apiv1search","title":"GET /api/v1/search","text":"<p>Search remote model sources.</p> <p>Query Parameters</p> Parameter Type Default Description <code>query</code> string <code>null</code> Free-text search query <code>source</code> string <code>\"huggingface\"</code> Source plugin to query <code>provider</code> string <code>null</code> Filter by author/organization <code>params</code> string <code>null</code> Parameter count (e.g., <code>\"7b\"</code>, <code>\"30b\"</code>) <code>size</code> string <code>null</code> Size constraint (e.g., <code>\"&lt;100gb\"</code>) <code>format</code> string <code>null</code> Model format (<code>gguf</code>, <code>safetensors</code>, <code>pytorch</code>) <code>task</code> string <code>null</code> Pipeline tag (e.g., <code>\"text-generation\"</code>) <code>license</code> string <code>null</code> License identifier (e.g., <code>\"apache-2.0\"</code>) <code>limit</code> int <code>20</code> Maximum results <p>Response <code>200</code></p> <pre><code>{\n  \"query\": \"llama\",\n  \"source\": \"huggingface\",\n  \"count\": 3,\n  \"results\": [\n    {\n      \"source\": \"huggingface\",\n      \"model_id\": \"meta-llama/Llama-3.1-8B-Instruct\",\n      \"model_name\": \"Llama-3.1-8B-Instruct\",\n      \"author\": \"meta-llama\",\n      \"total_size_bytes\": 16106127360,\n      \"file_count\": 5,\n      \"parameter_count\": 8,\n      \"architecture\": \"llama\",\n      \"format\": [\"safetensors\"],\n      \"quantization\": null,\n      \"tags\": [\"text-generation\"],\n      \"license\": \"llama3.1\",\n      \"downloads\": 985000,\n      \"likes\": 2400,\n      \"created_at\": \"2024-07-23T10:00:00+00:00\",\n      \"updated_at\": \"2024-12-01T08:30:00+00:00\",\n      \"web_url\": \"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct\",\n      \"repo_url\": \"https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/tree/main\"\n    }\n  ]\n}\n</code></pre>"},{"location":"reference/rest-api/#get-apiv1models","title":"GET /api/v1/models","text":"<p>List locally downloaded models.</p> <p>Query Parameters</p> Parameter Type Default Description <code>source</code> string <code>null</code> Filter by source name <p>Response <code>200</code></p> <pre><code>{\n  \"count\": 1,\n  \"models\": [\n    {\n      \"source\": \"huggingface\",\n      \"model_id\": \"Qwen/Qwen2.5-7B-Instruct\",\n      \"path\": \"/data/models/huggingface/Qwen/Qwen2.5-7B-Instruct\",\n      \"size_bytes\": 14495514624,\n      \"downloaded_at\": \"2025-02-12T14:30:00.123456\",\n      \"last_used\": null,\n      \"files\": [\"model.safetensors\", \"config.json\", \"tokenizer.json\"],\n      \"metadata\": {}\n    }\n  ]\n}\n</code></pre>"},{"location":"reference/rest-api/#get-apiv1modelssourcemodel_id","title":"GET /api/v1/models/{source}/{model_id}","text":"<p>Get info for a specific model. Returns both local storage data and remote metadata when available.</p> <p>Path Parameters</p> Parameter Description <code>source</code> Source name (e.g., <code>huggingface</code>) <code>model_id</code> Model identifier (e.g., <code>Qwen/Qwen2.5-7B-Instruct</code>) <p>Response <code>200</code></p> <pre><code>{\n  \"local\": {\n    \"source\": \"huggingface\",\n    \"model_id\": \"Qwen/Qwen2.5-7B-Instruct\",\n    \"path\": \"/data/models/huggingface/Qwen/Qwen2.5-7B-Instruct\",\n    \"size_bytes\": 14495514624,\n    \"downloaded_at\": \"2025-02-12T14:30:00.123456\",\n    \"last_used\": null,\n    \"files\": [],\n    \"metadata\": {}\n  },\n  \"remote\": {\n    \"source\": \"huggingface\",\n    \"model_id\": \"Qwen/Qwen2.5-7B-Instruct\",\n    \"model_name\": \"Qwen2.5-7B-Instruct\",\n    \"author\": \"Qwen\",\n    \"total_size_bytes\": 14495514624,\n    \"file_count\": 8,\n    \"parameter_count\": 7,\n    \"architecture\": \"qwen\",\n    \"format\": [\"safetensors\"],\n    \"quantization\": null,\n    \"tags\": [],\n    \"license\": \"apache-2.0\",\n    \"downloads\": 892000,\n    \"likes\": 1800,\n    \"created_at\": \"\",\n    \"updated_at\": \"\",\n    \"web_url\": \"https://huggingface.co/Qwen/Qwen2.5-7B-Instruct\",\n    \"repo_url\": \"https://huggingface.co/Qwen/Qwen2.5-7B-Instruct/tree/main\"\n  }\n}\n</code></pre> <p>Response <code>404</code> \u2014 model not found locally or remotely.</p>"},{"location":"reference/rest-api/#delete-apiv1modelssourcemodel_id","title":"DELETE /api/v1/models/{source}/{model_id}","text":"<p>Remove a model from local storage.</p> <p>Path Parameters</p> Parameter Description <code>source</code> Source name <code>model_id</code> Model identifier <p>Response <code>200</code></p> <pre><code>{\n  \"deleted\": true,\n  \"model_id\": \"Qwen/Qwen2.5-7B-Instruct\",\n  \"source\": \"huggingface\"\n}\n</code></pre> <p>Response <code>404</code> \u2014 model not found.</p>"},{"location":"reference/rest-api/#post-apiv1downloads","title":"POST /api/v1/downloads","text":"<p>Download a model. Runs synchronously \u2014 set long client timeouts.</p> <p>Request Body</p> <pre><code>{\n  \"model_id\": \"Qwen/Qwen2.5-7B-Instruct\",\n  \"source\": \"huggingface\",\n  \"force\": false,\n  \"include_patterns\": null\n}\n</code></pre> Field Type Default Required Description <code>model_id</code> string Yes Model identifier <code>source</code> string <code>\"huggingface\"</code> No Source plugin name <code>force</code> bool <code>false</code> No Re-download even if present <code>include_patterns</code> list[string] <code>null</code> No Glob patterns to filter files (e.g., <code>[\"*Q4_K_M*\"]</code>) <p>Response <code>200</code></p> <pre><code>{\n  \"model_id\": \"Qwen/Qwen2.5-7B-Instruct\",\n  \"source\": \"huggingface\",\n  \"path\": \"/data/models/huggingface/Qwen/Qwen2.5-7B-Instruct\",\n  \"files\": [\"model.safetensors\", \"config.json\"],\n  \"size_bytes\": 14495514624\n}\n</code></pre> <p>Response <code>404</code> \u2014 model not found on remote source.</p> <p>Response <code>500</code> \u2014 download failed.</p>"},{"location":"reference/rest-api/#get-apiv1status","title":"GET /api/v1/status","text":"<p>Get storage statistics.</p> <p>Response <code>200</code></p> <pre><code>{\n  \"model_count\": 3,\n  \"total_size_bytes\": 94371840000,\n  \"storage_path\": \"/data/models\",\n  \"sources\": {\n    \"huggingface\": {\n      \"count\": 3,\n      \"size_bytes\": 94371840000\n    }\n  }\n}\n</code></pre>"},{"location":"reference/rest-api/#post-apiv1clean","title":"POST /api/v1/clean","text":"<p>Clean unused or all models.</p> <p>Request Body</p> <pre><code>{\n  \"unused\": true,\n  \"days\": 30,\n  \"all\": false,\n  \"dry_run\": false\n}\n</code></pre> Field Type Default Description <code>unused</code> bool <code>false</code> Remove models not used within <code>days</code> <code>days</code> int <code>30</code> Unused threshold in days <code>all</code> bool <code>false</code> Remove all models <code>dry_run</code> bool <code>false</code> List what would be removed without deleting <p>Response <code>200</code></p> <pre><code>{\n  \"removed\": 2,\n  \"freed_bytes\": 28991029248,\n  \"dry_run\": false,\n  \"models\": [\n    \"huggingface/Qwen/Qwen2.5-7B-Instruct\",\n    \"huggingface/meta-llama/Llama-3.2-3B-Instruct\"\n  ]\n}\n</code></pre>"},{"location":"reference/rest-api/#post-apiv1export","title":"POST /api/v1/export","text":"<p>Export model list.</p> <p>Request Body</p> <pre><code>{\n  \"format\": \"kitt\"\n}\n</code></pre> Field Type Default Description <code>format</code> string <code>\"kitt\"</code> Export format: <code>\"kitt\"</code> (path list) or <code>\"json\"</code> (full details) <p>Response <code>200</code> (kitt format)</p> <pre><code>{\n  \"format\": \"kitt\",\n  \"count\": 2,\n  \"content\": [\n    \"/data/models/huggingface/Qwen/Qwen2.5-7B-Instruct\",\n    \"/data/models/huggingface/meta-llama/Llama-3.1-8B-Instruct\"\n  ]\n}\n</code></pre> <p>Response <code>200</code> (json format)</p> <pre><code>{\n  \"format\": \"json\",\n  \"count\": 1,\n  \"content\": [\n    {\n      \"source\": \"huggingface\",\n      \"model_id\": \"Qwen/Qwen2.5-7B-Instruct\",\n      \"path\": \"/data/models/huggingface/Qwen/Qwen2.5-7B-Instruct\",\n      \"size_bytes\": 14495514624,\n      \"downloaded_at\": \"2025-02-12T14:30:00.123456\",\n      \"files\": [\"model.safetensors\", \"config.json\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"reference/rest-api/#error-responses","title":"Error Responses","text":"<p>All error responses follow this format:</p> <pre><code>{\n  \"detail\": \"Error description here\"\n}\n</code></pre> Status Code Meaning <code>400</code> Bad request (invalid source name, malformed input) <code>401</code> Unauthorized (missing or invalid API key) <code>404</code> Resource not found <code>422</code> Validation error (invalid request body) <code>500</code> Internal server error (download failure, etc.)"},{"location":"reference/storage-index/","title":"Storage Index","text":"<p>DEVON tracks all locally downloaded models in a JSON index file. This page documents the index location, format, and the methods available for interacting with it.</p>"},{"location":"reference/storage-index/#file-location","title":"File Location","text":"<pre><code>~/.cache/devon/index.json\n</code></pre> <p>The index file sits as a sibling to the <code>models/</code> directory inside the configured <code>storage.base_path</code> parent:</p> <pre><code>~/.cache/devon/\n\u251c\u2500\u2500 index.json       # Model index\n\u2514\u2500\u2500 models/          # Downloaded model files\n    \u2514\u2500\u2500 huggingface/\n        \u2514\u2500\u2500 Qwen/\n            \u2514\u2500\u2500 Qwen2.5-32B-Instruct/\n</code></pre>"},{"location":"reference/storage-index/#key-format","title":"Key Format","text":"<p>Each entry is keyed by <code>{source}::{model_id}</code>:</p> <pre><code>huggingface::Qwen/Qwen2.5-32B-Instruct\n</code></pre>"},{"location":"reference/storage-index/#entry-schema","title":"Entry Schema","text":"<pre><code>{\n  \"source\": \"huggingface\",\n  \"model_id\": \"Qwen/Qwen2.5-32B-Instruct\",\n  \"path\": \"/home/user/.cache/devon/models/huggingface/Qwen/Qwen2.5-32B-Instruct\",\n  \"metadata\": { },\n  \"files\": [\"model.safetensors\", \"config.json\"],\n  \"downloaded_at\": \"2025-02-12T14:30:00.123456\",\n  \"last_used\": \"2025-02-12T15:00:00.123456\",\n  \"size_bytes\": 67108864000\n}\n</code></pre> Field Type Description <code>source</code> string Source plugin that provided the model <code>model_id</code> string Full model identifier <code>path</code> string Absolute path to the model directory on disk <code>metadata</code> object Serialized <code>ModelMetadata</code> (see Model Metadata) <code>files</code> list[string] Filenames stored in the model directory <code>downloaded_at</code> string ISO 8601 timestamp of when the download completed <code>last_used</code> string ISO 8601 timestamp updated each time the model is accessed <code>size_bytes</code> int Total size in bytes, calculated at registration time"},{"location":"reference/storage-index/#modelstorage-methods","title":"ModelStorage Methods","text":"<p>The <code>ModelStorage</code> class in <code>devon.storage.organizer</code> provides the following methods for managing the index:</p> Method Description <code>register_model(metadata, path, files)</code> Add a new entry to the index after download <code>list_local_models()</code> Return all entries in the index <code>is_downloaded(source, model_id)</code> Check whether a model key exists <code>get_model_entry(source, model_id)</code> Retrieve a single entry by key <code>delete_model(source, model_id)</code> Remove the entry and its files from disk <code>get_total_size()</code> Sum <code>size_bytes</code> across all entries <code>mark_used(source, model_id)</code> Update <code>last_used</code> to the current timestamp"},{"location":"reference/cli/","title":"CLI Reference","text":"<p>DEVON exposes nine commands through the <code>devon</code> entry point:</p> Command Purpose <code>devon search</code> Search for models on a remote source <code>devon download</code> Download a model by ID or URL <code>devon list</code> List locally downloaded models <code>devon info</code> Show detailed metadata for a model <code>devon status</code> Display vault disk usage and statistics <code>devon clean</code> Remove unused or all cached models <code>devon export</code> Export model paths for KITT or JSON <code>devon remove</code> Delete a specific model from the vault <code>devon serve</code> Start the REST API server <p>All commands support <code>--help</code> for inline usage information.</p>"},{"location":"reference/cli/#devon","title":"devon","text":"<p>DEVON - Discovery Engine and Vault for Open Neural models</p> <p>Discover, download, and manage LLM models with ease.</p> <p>Examples:   devon search --provider qwen --params 30b   devon download https://huggingface.co/Qwen/Qwen2.5-32B-Instruct   devon list</p> <p>Usage:</p> <pre><code>devon [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--version</code> boolean Show the version and exit. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#clean","title":"clean","text":"<p>Clean up downloaded models.</p> <p>Examples:   devon clean --unused --days 30   devon clean --all   devon clean --unused --dry-run</p> <p>Usage:</p> <pre><code>devon clean [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--unused</code> boolean Remove unused models <code>False</code> <code>--days</code> integer Consider unused after N days <code>30</code> <code>--all</code> boolean Remove all downloaded models <code>False</code> <code>--dry-run</code> boolean Show what would be removed without removing <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#download","title":"download","text":"<p>Download a model by ID or URL.</p> <p>Examples:   devon download https://huggingface.co/Qwen/Qwen2.5-32B-Instruct   devon download Qwen/Qwen2.5-32B-Instruct --source huggingface   devon download bartowski/Meta-Llama-3.1-8B-Instruct-GGUF --include 'Q4_K_M'</p> <p>Usage:</p> <pre><code>devon download [OPTIONS] MODEL_IDENTIFIER\n</code></pre> <p>Options:</p> Name Type Description Default <code>--source</code>, <code>-s</code> text Source (if not URL) <code>Sentinel.UNSET</code> <code>--force</code>, <code>-f</code> boolean Re-download if exists <code>False</code> <code>--include</code>, <code>-i</code> text File patterns to include (e.g. 'Q4_K_M') <code>Sentinel.UNSET</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#export","title":"export","text":"<p>Export model list for KITT.</p> <p>Examples:   devon export --format kitt -o models.txt   kitt run --model-list models.txt --engine vllm</p> <p>Usage:</p> <pre><code>devon export [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--format</code> choice (<code>kitt</code> | <code>json</code>) N/A <code>kitt</code> <code>--output</code>, <code>-o</code> path N/A <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#info","title":"info","text":"<p>Show detailed info about a model.</p> <p>Example:   devon info Qwen/Qwen2.5-32B-Instruct</p> <p>Usage:</p> <pre><code>devon info [OPTIONS] MODEL_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--source</code>, <code>-s</code> text N/A <code>huggingface</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#list-models","title":"list-models","text":"<p>List locally downloaded models.</p> <p>Example:   devon list   devon list --source huggingface</p> <p>Usage:</p> <pre><code>devon list-models [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--source</code>, <code>-s</code> text Filter by source <code>Sentinel.UNSET</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#remove","title":"remove","text":"<p>Remove a downloaded model.</p> <p>Examples:   devon remove Qwen/Qwen2.5-32B-Instruct   devon remove bartowski/Meta-Llama-3.1-8B-Instruct-GGUF -y</p> <p>Usage:</p> <pre><code>devon remove [OPTIONS] MODEL_ID\n</code></pre> <p>Options:</p> Name Type Description Default <code>--source</code>, <code>-s</code> text Model source <code>huggingface</code> <code>--yes</code>, <code>-y</code> boolean Skip confirmation prompt <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#search","title":"search","text":"<p>Search for models matching criteria.</p> <p>Examples:   devon search --provider qwen --params 30b --size \"&lt;100gb\"   devon search \"llama 3\" --format gguf</p> <p>Usage:</p> <pre><code>devon search [OPTIONS] [QUERY]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--provider</code>, <code>-p</code> text Filter by provider/author <code>Sentinel.UNSET</code> <code>--params</code> text Parameter count (e.g., 7b, 30b) <code>Sentinel.UNSET</code> <code>--size</code> text Size constraint (e.g., &lt;100gb) <code>Sentinel.UNSET</code> <code>--format</code>, <code>-f</code> text Model format (gguf, safetensors) <code>Sentinel.UNSET</code> <code>--task</code>, <code>-t</code> text Task type <code>Sentinel.UNSET</code> <code>--license</code>, <code>-l</code> text License type <code>Sentinel.UNSET</code> <code>--limit</code> integer Max results <code>20</code> <code>--source</code> text Source to search <code>huggingface</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#serve","title":"serve","text":"<p>Start the DEVON REST API server.</p> <p>Requires the 'api' extras: poetry install --extras api</p> <p>Examples:   devon serve   devon serve --host 0.0.0.0 --port 9000</p> <p>Usage:</p> <pre><code>devon serve [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--host</code> text Bind address <code>127.0.0.1</code> <code>--port</code> integer Port number <code>8000</code> <code>--reload</code> boolean Enable auto-reload (dev only) <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"reference/cli/#status","title":"status","text":"<p>Show storage status and statistics.</p> <p>Usage:</p> <pre><code>devon status [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--help</code> boolean Show this message and exit. <code>False</code>"}]}